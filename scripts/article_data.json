[
    {
        "doi": "10.6120\/JoEMLS.2015.523\/0027.RS.AM",
        "links": "http:\/\/joemls.dils.tku.edu.tw\/fulltext\/52\/52-3\/269-298.pdf",
        "abstract": "In this study we analyzed and discussed that the MIS-related journals under the ISI subject category of IS&LS are simultaneously given with subject category Management, using methods of topic modeling, journal clustering and subject category prediction. In the experiment of journal clustering, all journals under subject category Management and other journals also having similar topical features can be gathered into a cluster, and \u201cmanagement\u201d is their common and the most distinct topic. Because the journals belonged to this cluster are almost same to those in the MIS clusters generated by the previous studies, we considered it as the MIS cluster in this study. In the second experiment, we used the classification and regression tree (CART) technique to predict assignment of subject category with that the journals in the original subject category Management and in the MIS cluster produced in this study as positive examples, respectively. The trees generated by the two tests both used the occurring probabilities of the topic \u201cmanagement\u201d as the main classification rule. However, in the latter test, we did not only obtain a simpler classification tree but also had a result with less predicting errors. This means that if all journals in the MIS cluster could be given with subject category Management, the retrieval results can be more effective and complete.",
        "title": "A Study of the Subject Categorization of the MIS-related Journals in the ISI Databases Using Topical Features in the Text Content and Machine Learning Methods",
        "authors": [
            "Sung-Chien Lin"
        ],
        "year": "2015"
    },
    {
        "doi": "10.22133\/ijwr.2022.342312.1118",
        "links": "https:\/\/ijwr.usc.ac.ir\/article_154774_9ad3ee7c86e97303ee0b86fbd33d1d11.pdf",
        "abstract": "Community Question Answering has a crucial role in almost all societies nowadays. It is important for the owners of a community to be able to make it better and more reliable. One way to achieve this, is to find the users who have more knowledge, expertise, experience and skill and can well share their knowledge with others (which we call experts and aim to encourage them to be more active in the website). One method to use is to identify expert users, and whenever a new question is asked, we suggest this question to them to check and answer if its in their area of expertise. One way to encourage users to post replies, is to use gameplay techniques such as assigning points and badges to users. But as we will discuss, this method does not always detect expert users well, because some users will try to have small and insignificant but numerous activities that will make them gain a lot of points, however they are not experts. In this study, we examine the methods by which experts in a question-and-answer system can be found, and try to evaluate and compare these methods, use their ideas and positive points, and add our own new ideas to a new way of finding them. We used some ideas such as profile making for users, categorize users\u2019 expertise, A-Priori algorithm and showed that neural networks method results the best for the purpose of expert detection.",
        "title": "Expert Detection In Question Answer Communities",
        "authors": [
            "Hamed Salimian",
            "Mohammad Amin Fazli",
            "Jafar Habibi "
        ],
        "year": "2022"
    },
    {
        "doi": "10.24874\/PES.SI.24.03.006",
        "links": "https:\/\/pesjournal.net\/journal\/v6-n4\/32.pdf",
        "abstract": "Breast cancer (BC) ranks the second most prevalent cancer among women globally and is the leading cause of female mortality. The conventional method for BC detection primarily relies on biopsy; this might be time-consuming and error prone. The substantial lives lost due to BC underscores its significant threat. Mitigating this threat focuses on early detection and prevention by adopting novel techniques. Many researchers have turned to Machine Learning algorithms to develop prognosis systems. We employ a combination of deep learning (DL) and machine learning (ML) algorithms for BC identification. Our approach is a hybrid Convolutional Neural Network (CNN) model, which performs better than other experimental and existing models. This model effectively categorizes histopathological images into either benign or malignant classes. We explored various methodologies, including CNN, CNN in conjunction with Support Vector Machine (SVM), CNN with Random Forest, and VGG-16 combined with XGBOOST. This research seeks to enhance the accuracy and efficiency of BC diagnosis. It contributes to more effective early detection and improved patient outcomes.",
        "title": "SMART HYBRID MODELS FOR IMPROVED BREAST CANCER DETECTION",
        "authors": [
            "Nageswara Rao Gali ",
            "Panduranga Vital Terlapu ",
            "Yasaswini Mandavakuriti",
            "Sai Manoj Somu ",
            "Madhavi Varanasi ",
            "Vijay Telugu ",
            "Maheswara Rao V V R "
        ],
        "year": "2024"
    },
    {
        "doi": "10.37897\/RJN.2020.3.1",
        "links": "https:\/\/rjn.com.ro\/articles\/2020.3\/RJN_2020_3_Art-01.pdf",
        "abstract": "The palmomental reflex is a well-known neurologic sign, however its current diagnostic value is considered limited and its role in the neurologic examination has been questioned. Given that a century has passed since its first description in 1920, we conducted a review of the literature about the palmomental reflex, beginning with its physiology and prevalence in the general population, and continuing with its possible diagnostic and prognostic value in relation to neurologic disorders such as dementia, Parkinson disease, amyotrophic lateral sclerosis, stroke and frontal lobe disease.",
        "title": "The palmomental reflex \u2013 overview and clinical significance",
        "authors": [
            "Ioan-Cristian Lupescu",
            "Adriana Octaviana Dulamea",
            "Daniela Anghel"
        ],
        "year": "2020"
    },
    {
        "doi": "10.14311\/bit.2022.01.17",
        "links": "http:\/\/bit.fsv.cvut.cz\/issues\/01-22\/full_01-22_17.pdf",
        "abstract": "Function - The goal of this particular paper is presenting a novel framework for strategic decision making utilizing Big Data Analytics methodology. Design\/methodology\/approach - In this particular research, 2 distinct machine learning algorithms, Random Forest as well as Artificial Neural Networks are used to forecast export volumes working with a considerable level of open industry information. The forecasted values are in the Boston Consulting Group Matrix to conduct strategic industry analysis. Results - The proposed technique is validated utilizing a hypothetical case study of a Chinese business exporting freezers and refrigerators. The results indicate the proposed methodology makes exact trade forecasts and helps to conduct strategic industry evaluation properly. Furthermore, the RF performs much better compared to the ANN in terminology of forecast accuracy. Investigate limitations\/implications - This analysis provides just one case study to evaluate the proposed methodology. In future scientific studies, the validity of the suggested technique is further generalized in various item groups and nations. Functional implications - In present day extremely competitive business environment, a good strategic industry evaluation involves exporters or importers making much better predictions along with strategic choices. To us the proposed BDA based strategy, businesses may efficiently determine business opportunities and alter their strategic choices appropriately. Originality\/value - This's the very first study to provide a holistic methodology for strategic industry evaluation using BDA. The proposed methodology effectively forecasts global trade volumes and helps with the strategic decision making practice through succeeding insights into worldwide marketplaces.",
        "title": "Decision-making in large corporations - role of big data analytics & data mining",
        "authors": [
            "Christophar Nicholas Hendstein",
            "Hiroshi Akeera Katsu"
        ],
        "year": "2022"
    },
    {
        "doi": "10.14202\/vetworld.2021.829-834",
        "links": "http:\/\/www.veterinaryworld.org\/Vol.14\/April-2021\/2.pdf",
        "abstract": "Background and Aim: Fetal biparietal diameter (BPD) is a feasible parameter to predict canine parturition date due to its inverted correlation with days before parturition (DBP). Although such a relationship is generally described using a simple linear regression (SLR) model, the imprecision of this model in predicting the parturition date in small- to medium-sized dogs is a common problem among veterinarian practitioners. Support vector regression (SVR) is a useful machine learning model for prediction. This study aimed to compare the accuracy of SVR with that of SLR in predicting DBP.\r\n\r\nMaterials and Methods: After measuring 101 BPDs in 35 small- to medium-sized pregnant bitches, we fitted the data to the routine SLR model and the SVR model using three different kernel functions, radial basis function SVR, linear SVR, and polynomial SVR. The predicted DBP acquired from each model was further utilized for calculating the coefficient of determination (R2), mean absolute error, and mean squared error scores for determining the prediction accuracy.\r\n\r\nResults: All SVR models were more accurate than the SLR model at predicting DBP. The linear and polynomial SVRs were identified as the two most accurate models (p<0.01).\r\n\r\nConclusion: With available machine learning software, linear and polynomial SVRs can be applied to predicting DBP in small- to medium-sized pregnant bitches.",
        "title": "Support vector regression algorithm modeling to predict the parturition date of small - to medium-sized dogs using maternal weight and fetal biparietal diameter",
        "authors": [
            "Thanida Sananmuang",
            "Kanchanarat Mankong",
            "Suppawiwat Ponglowhapan",
            "Kaj Chokeshaiusaha"
        ],
        "year": "2021"
    },
    {
        "doi": "10.3897\/natureconservation.55.121181",
        "links": "https:\/\/natureconservation.pensoft.net\/article\/121181\/download\/pdf\/",
        "abstract": "The current study employed diverse statistical and machine learning techniques to investigate the biodiversity and spatial distribution of phytoplankton cysts in the Black Sea. The MaxEnt distribution modeling technique was used to forecast the habitat suitability for the cysts of three potentially toxic microalgal taxa (Lingulodinium polyedra, Polykrikos hartmannii, and Alexandrium spp.). The key variables controlling the habitat suitability of Alexandrium spp. and L. polyedra were nitrates and temperature, while for the P. hartmannii cysts, nitrates and salinity. The region with the highest likelihood of L. polyedra cyst occurrence appears to be in the western coastal and shelf waters, which coincides with the areas where L. polyedra red tides have been documented. The projected habitat suitability of the examined species partially overlapped, perhaps as a result of their cohabitation within the phytoplankton community and shared preferences for specific environmental conditions, demonstrating similar survival strategies. The north-western region of the Black Sea was found to be the most suitable environment for the studied potentially toxic species, presumably posing a greater risk for the onset of blooming events. Two distinct aspects of cysts\u2019 ecology and settlement were observed: the dispersal of cysts concerns their movement within the water column from one place to another prior to settling, while habitat suitability pertains to the particular environment required for their survival, growth, and germination. Therefore, it is crucial to validate the model in order to accurately determine a suitable habitat as well as understand the transportation patterns linked to the particular hydrodynamic properties of the water column and the distinct features of the local environment.",
        "title": "Spatial distribution models and biodiversity of phytoplankton cysts in the Black Sea",
        "authors": [
            "Nina Dzhembekova",
            "Ivelina Zlateva",
            "Fernando Rubino",
            "Manuela Belmonte",
            "Valentina Doncheva",
            "Ivan Popov",
            "Snejana Moncheva"
        ],
        "year": "2024"
    },
    {
        "doi": "10.36660\/abc.20220484",
        "links": "http:\/\/www.scielo.br\/scielo.php?script=sci_arttext&pid=S0066-782X2023000500308&lng=pt&tlng=pt",
        "abstract": "Resumo  Fundamento  A mensura\u00e7\u00e3o indireta da press\u00e3o sangu\u00ednea (PS) \u00e9 sabidamente influenciada por diversos fatores como t\u00e9cnica, observador e equipamento, mas a influ\u00eancia da composi\u00e7\u00e3o do bra\u00e7o ainda n\u00e3o foi investigada.  Objetivo  Identificar a influ\u00eancia da gordura do bra\u00e7o sobre a medida indireta da press\u00e3o sangu\u00ednea, utilizando modelos de infer\u00eancia estat\u00edstica e machine learning.  M\u00e9todos  Estudo transversal, com 489 adultos jovens saud\u00e1veis de 18 a 29 anos de idade. Foram medidos comprimento (COB), circunfer\u00eancia do bra\u00e7o (CB) e \u00edndice de gordura do bra\u00e7o (IGB). A PS foi mensurada em ambos os bra\u00e7os, simultaneamente. Os dados foram processados utilizando-se Python 3.0 e pacotes espec\u00edficos para an\u00e1lise descritiva, regress\u00e3o e clusteriza\u00e7\u00e3o. Um n\u00edvel de signific\u00e2ncia de 5% foi adotado para todos os c\u00e1lculos.  Resultados  A PS e as medidas antropom\u00e9tricas foram diferentes entre os hemicorpos. A press\u00e3o sangu\u00ednea sist\u00f3lica (PAS), COB, e IGB foram maiores no bra\u00e7o direito (BD), enquanto CB foi similar em compara\u00e7\u00e3o ao bra\u00e7o esquerdo. COB e CB apresentaram correla\u00e7\u00e3o positiva com a PAS. Conforme o modelo de regress\u00e3o, para determinado valor de CB e COB, a leitura da PAS poder\u00e1 ter uma redu\u00e7\u00e3o m\u00e9dia de 1,80 mmHg no BD, e 1,62 mmHg no bra\u00e7o esquerdo, a cada 10% de aumento na IGB. A clusteriza\u00e7\u00e3o corroborou os resultados da regress\u00e3o.  Conclus\u00e3o  Foi encontrada uma influ\u00eancia significativa do IGB sobre a leitura da PS. A PAS teve correla\u00e7\u00e3o positiva com COB e CB, e correla\u00e7\u00e3o negativa com IGB, o que sugere a necessidade de mais investiga\u00e7\u00f5es sobre a rela\u00e7\u00e3o da PS com as fra\u00e7\u00f5es de gordura e m\u00fasculo do bra\u00e7o.",
        "title": "Influ\u00eancia da Gordura do Bra\u00e7o sobre Medida Indireta da Press\u00e3o Sangu\u00ednea: Uma Abordagem Estat\u00edstica e de Machine Learning",
        "authors": [
            "Pa\u00f4la de Oliveira Souza",
            "Jos\u00e9 Maria Parente de Oliveira",
            "Let\u00edcia Helena Janu\u00e1rio"
        ],
        "year": "2023"
    },
    {
        "doi": "10.3897\/rio.8.e95724",
        "links": "https:\/\/riojournal.com\/article\/95724\/download\/pdf\/",
        "abstract": "In academic research virtually every field has increased its use of digital and computational technology, leading to new scientific discoveries, and this trend is likely to continue. Reliable and efficient scholarly research requires researchers to be able to validate and extend previously generated research results. In the digital era, this implies that digital objectsKahn and Wilensky 2006 used in research should be Findable, Accessible, Interoperable and Reusable (FAIR). These objects include (but are not limited to) data, software, models (for example, machine learning), representations of physical objects, virtual research environments, workflows, etc. Leaving any of these digital objects out of the FAIR process may result in a loss of academic rigor and may have severe consequences in the long term for the field, such as a reproducibility crisis. In this extended abstract, we focus on research software as a FAIR digital object (FDO).The FDO framework De Smedt et al. 2020 describes FDOs as being actionable units of knowledge, which can be aggregated, analyzed, and processed by different types of algorithms. Such algorithms must be implemented by software in one form or another. The framework also describes large software stacks supporting FDOs enabling responsible data science and increasing reproducibility. This implies that software is a key ingredient of the FDO framework, and should adhere to the FAIR principles. Software plays multiple roles: it is a DO itself, it is responsible for creating new FDOs (e.g., data) and it helps to make them available to the public (e.g., via repositories and registries). However there is a need to specify in more detail how non-data DOs, in particular software, fit in this framework.Different classes of digital objects have different intrinsic properties and ways to relate to other DOs. This means that while they, in principle, are subject to the high-level FAIR principles, there are also differences depending on their type and properties, requiring an adaptation so FAIR implementations are more aligned to the digital object itself. This holds true in particular to software. Software has intrinsic properties (executability, composite nature, development practices, continuous evolution and versioning, and packaging and distribution) and specific needs that must be considered by the FDO framework. For example, open source software is typically developed in the open on social coding platforms, where releases are distributed through package management systems, unlike data that is typically published in archival repositories. These social coding platforms do not provide long term archiving, permanent identifiers, or metadata, and package management systems, while somewhat better, similarly do not make a commitment to long term archiving, do not use identifiers that fit the scholarly publication system well, and provide metadata that may be missing key elements. The FAIR for research software (FAIR4RS, Chue Hong et al. 2021) working group has dedicated significant effort in building a community consensus around developing FAIR principles that are customized for research software, providing methods for researchers to understand and address these gaps.In this presentation we will highlight the importance of software for the FAIR landscape and why different (but related) FAIR principles are needed for software (vs those originally developed for data). Our goal here is to contribute to building an FDO landscape together, where we consider all different types of digital objects that are essential in today's research, and we are enthusiastic about contributing our expertise on research software in helping shape this landscape.",
        "title": "How does software fit into the FDO landscape?",
        "authors": [
            "Carlos Martinez-Ortiz",
            "Carole Goble",
            "Daniel Katz",
            "Tom Honeyman",
            "Paula Martinez",
            "Michelle Barker",
            "Leyla Jael Castro",
            "Neil Chue Hong",
            "Morane Gruenpeter",
            "Jennifer Harrow",
            "Anna-Lena Lamprecht",
            "Fotis Psomopoulos"
        ],
        "year": "2022"
    },
    {
        "doi": "10.25206\/2588-0373-2024-8-2-5-12",
        "links": "https:\/\/www.omgtu.ru\/general_information\/media_omgtu\/journal_of_omsk_research_journal\/files\/arhiv\/2024\/%D0%A2.8,%20%E2%84%962%20(%D0%90%D0%A0%D0%B8%D0%AD%D0%9C)\/5-12%20%D0%92%D0%B5%D0%B4%D1%80%D1%83%D1%87%D0%B5%D0%BD%D0%BA%D0%BE%20%D0%92.%20%D0%A0.,%20%D0%A0%D0%B5%D0%B7%D0%B0%D0%BD%D0%BE%D0%B2%20%D0%95.%20%D0%9C.,%20%D0%A1%D1%82%D0%B0%D1%80%D0%B8%D0%BA%D0%BE%D0%B2%20%D0%90.%20%D0%9F.,%20%D0%9A%D1%83%D1%88%D0%BD%D0%B0%D1%80%D0%B5%D0%BD%D0%BA%D0%BE%20%D0%90.%20%D0%92.,%20%D0%A1%D1%83%D1%80%D0%BE%D0%B2%D1%86%D0%B5%D0%B2%20%D0%9F.%20%D0%90.,%20%D0%9A%D0%B8%D1%85%D1%82%D0%B5%D0%BD%D0%BA%D0%BE%20%D0%92.%20%D0%90..pdf",
        "abstract": "The article discusses the possibility of calculating the expected energy demand based on big data and\r\nmachine learning for the energy technological processes in oil refineries. In order to obtain predictive\r\ndata, linear regression, machine learning, and neural networks are proposed to be used to build\r\na mathematical model. The advantages and disadvantages of these methods are discussed, and the\r\naccuracy of the models is compared with the possibility of interpreting them. Thanks to the use of\r\nadvanced statistical methods, the variability of energy consumption can be interpreted through factor\r\nanalysis. Through pilot tests, the practical significance of these proposed methods for their practical use\r\nin an energy management system is demonstrated, as well as the transition to statistical control of the\r\nprocess.",
        "title": "On the choice of the method of dynamic rationing of energy resources in oil refineries",
        "authors": [
            "V. R. Vedruchenko",
            "E. M. Rezanov",
            "A. P. Starikov",
            "A. V. Kushnarenko",
            "P. A. Surovtsev",
            "V. A. Kikhtenko"
        ],
        "year": "2024"
    },
    {
        "doi": "10.1590\/0104-530x4158-20",
        "links": "http:\/\/www.scielo.br\/scielo.php?script=sci_arttext&pid=S0104-530X2020000300214&tlng=en",
        "abstract": "Abstract: The objective of this study is to develop a quantitative tool, based on Machine Learning and Geomarketing to identify business opportunities and contribute to the strategic process of local choice of franchises\u2019 network selecting regions that have a high demand forecast and a lack of product supply. In addition, we conducted a qualitative analysis of the selected business places based on defined criteria. This prediction is given by constructing a consumption pattern, defined by a classifier, based on the characteristics of the reserved rights. Initially, for a better understanding on this subject, a theoretical background was made covering the main concepts about Geomarketing and Machine Learning and its applications. After that for a demonstration of the results, we opted for the application of the method for the market of fine chocolates (Cacau-Show) in the Distrito Federal. The main databases used in this paper were Pesquisa de Or\u00e7amentos Familiares and from Instituto Brasileiro de Estat\u00edstica e Geografia (IBGE). As a result, the Standardized Spend was obtained, which indicates the requirement for each Censitar Sector, as georeferenced information of the competition, containing 44 stores that have as their main product of fine chocolate, and as digital meshes of the Federal District. The crossing is available for the elaboration of a map that facilitates the identification of the business opportunities for the market of fine chocolates in the Distrito Federal, Brazil.",
        "title": "Mapping regional business opportunities using geomarketing and machine learning",
        "authors": [
            "Marcelo Fernando Felix de Oliveira",
            "Pedro Henrique Melo Albuquerque",
            "Peng Yao Hao",
            "Pedro Alexandre Henrique"
        ],
        "year": "2020"
    },
    {
        "doi": "10.5281\/zenodo.7832714",
        "links": "http:\/\/fs.unm.edu\/NSS\/NeutrosophicSpeechRecognition4.pdf",
        "abstract": "It is well known that the unpredictable speech production brought on by stress from the task at hand has a significant negative impact on the performance of speech processing algorithms. Speech therapy benefits from being able to detect stress in speech. Speech processing performance suffers noticeably when perceptually produced stress causes variations in speech production. Using the acoustic speech signal to objectively characterize speaker stress is one method for assessing production variances brought on by stress. Real-world complexity and ambiguity make it difficult for decision-makers to express their conclusions with clarity in their speech. In particular, the Neutrosophic speech algorithm is used to encode the language variables because they cannot be computed directly. Neutrosophic sets are used to manage indeterminacy in a practical situation. Existing algorithms are used except for stress on Neutrosophic speech recognition. The creation of algorithms that calculate, categorize, or differentiate between different stress circumstances. Understanding stress and developing strategies to combat its effects on speech recognition and human-computer interaction system are the goals of this recognition.",
        "title": "Neutrosophic speech recognition Algorithm for speech under stress by Machine learning",
        "authors": [
            "D. Nagarajan",
            "Said Broumi",
            "Florentin Smarandache"
        ],
        "year": "2023"
    },
    {
        "doi": "10.5281\/zenodo.6975670",
        "links": "https:\/\/irjstem.com\/wp-content\/uploads\/2022\/08\/IRJSTEM-Volume2_No2_Paper3.pdf",
        "abstract": "Diabetes is actually one of the primary causes of human mortality. Diabetes is an intense disease affecting various parts of the human body. Diabetes can rise long-range complications including, renal failure and cardiac failure. It is therefore imperative that diabetes be diagnosed in a timely manner to people all over the world. This study develops a method for diabetic classification using machine learning techniques. In this study, Support Vector Machine (SVM) is employed to classify the diabetic disease into two classes based on its different functions, namely, linear, polynomial, and sigmoid functions. The evaluation performance of this study is performed before and after applying the pre-processing stage using different standard criteria. The higher results were obtained by polynomial function 83.77% for accuracy, 86.07% for sensitivity, and 81.97% for specificity. Finally, a comparison between this study and some of the previous studies was addressed, based on the comparison it is shown that this study has a better ability to classify diabetic disease than previous studies.",
        "title": "Support vector machine classification learning algorithm for diabetes prediction",
        "authors": [
            "Renas Rajab Asaad"
        ],
        "year": "2022"
    },
    {
        "doi": "10.22133\/ijwr.2024.449726.1211",
        "links": "https:\/\/ijwr.usc.ac.ir\/article_197180_ca24efdc59c110e9cfdd5830269b4608.pdf",
        "abstract": "Lung infection represents one of the most perilous indicators of Covid-19. The most efficient diagnostic approach entails the analysis of CT scan images. Utilizing deep learning algorithms and machine vision, computer scientists have devised a method for automated detection of this disease. This study proposes a two-stage approach to identifying lung infection. In the initial stage, image features are extracted through a transfer learning framework employing ResNet50, with the last two layers being fixed. Subsequently, a CNN neural network is constructed for image detection and categorization in the second stage. By employing superior image feature selection and minimizing non-informative features, this proposed method achieves impressive accuracy metrics: 98.99% accuracy, 98.91% sensitivity, and 99.10% specificity. Furthermore, a comparative analysis is conducted between this method and six other architectures (Inception, InceptionResNetV2, ResNet101, ResNet152, VGG16, VGG19), with and without transfer learning. The findings demonstrate that the proposed method attains 98% accuracy on test data, without succumbing to overfitting.",
        "title": "A Two-Stage Method for Diagnosing COVID-19, Leveraging CNN, and Transfer Learning on CT Scan Images",
        "authors": [
            "Touba torabipour",
            "Abolfazl Gandomi ",
            "Mohammad Ghanimi"
        ],
        "year": "2023"
    },
    {
        "doi": "10.1590\/1678-992x-2023-0002",
        "links": "http:\/\/www.scielo.br\/scielo.php?script=sci_arttext&pid=S0103-90162024000100401&lng=en&tlng=en",
        "abstract": "ABSTRACT This study aimed to evaluate the use of decision trees to select sows based on the production parameters of parity order (PO) 1 sows from a commercial herd. Data were collected at a piglet production unit with a capacity of housing 5,500 sows in collective pens. Piglet production and sow culling information was collected from PO1 and PO2 sows. The period from January 2017 to March 2020 was analyzed. The correlation analysis was used to identify the influence of the production parameters on sow culling after exploring the database using the graphical analysis and descriptive statistics. The ANOVA was applied to evaluate differences in the response variables between culled and unculled sows. Two models were proposed using the decision tree method: model 1 referred to sow culling, and model 2 comprised the total number of liveborn piglets (TBA). The calculated value was close to 0, although the correlations of the production parameters with culling were statistically significant. The mean number of weaned piglets was higher for unculled sows in PO1 (p < 0.05). The number of weaned piglets, total number of liveborn piglets, and weaning-service interval did not differ in the unculled and culled sows in PO2 (p > 0.05). Using a confusion matrix as a metric tool, the decision tree method used in this study provided consistent results for this database, indicating its possible use for decision-making in sow selection.",
        "title": "Decision trees as a tool for selecting sows in commercial herds",
        "authors": [
            "Jo\u00e3o Ot\u00e1vio Hilgemberg",
            "Ines Andretta",
            "Alexandre Bonadiman Mariani",
            "Alisson Neimaier",
            "Marcio Valk",
            "Fernando Bittarello",
            "Rafaela Hilgemberg",
            "Cheila Roberta Lehnen"
        ],
        "year": "2023"
    },
    {
        "doi": "10.1590\/1980-5373-mr-2016-0280",
        "links": "http:\/\/www.scielo.br\/scielo.php?script=sci_arttext&pid=S1516-14392016000601253&tlng=en",
        "abstract": "Hot compression tests of as-cast Ti-6Al-2Zr-1Mo-1V alloy in a wide temperature range of 1073-1323 K and strain rate range of 0.01-10 s-1 were conducted by a servo-hydraulic and computer-controlled Gleeble-1500 machine. The hot flow behaviors of Ti-6Al-2Zr-1Mo-1V alloy show highly non-linear relationships with strain, strain rate and temperature. In order to accurately and effectively characterize the complex flow behaviors, support vector regression (SVR) which is a machine learning method was combined with Genetic Algorithm (GA) to characterize the flow behaviors, namely, the GA-SVR. The study abilities, generation abilities, and modeling efficiencies of the improved Arrhenius-type constitutive model, ANN, and GA-SVR for flow behaviors of as-cast Ti-6Al-2Zr-1Mo-1V alloy were detailedly compared. Comparison results show that the study ability of the GA-SVR is as strong as the ANN. The generation abilities and modeling efficiencies of these models were shown as follows in ascending order: the improved Arrhenius-type constitutive model < ANN < GA-SVR. Based on the established GA-SVR, the continuously three-dimensional relationships among flow stress, temperature, strain, and strain rate were constructed, which improve the simulation accuracy and related research fields where stress-strain data play important roles.",
        "title": "Numerical Description of Hot Flow Behaviors at Ti-6Al-2Zr-1Mo-1V Alloy By GA-SVR and Relative Applications",
        "authors": [
            "Guo-Zheng Quan",
            "Zhi-hua Zhang",
            "Yuting Zhou",
            "Tong Wang",
            "Yu-feng Xia"
        ],
        "year": "2016"
    },
    {
        "doi": "10.14456\/sjst-psu.2022.61",
        "links": "https:\/\/rdo.psu.ac.th\/sjst\/journal\/44-2\/21.pdf",
        "abstract": "This paper aims to introduce various types of useful operations on fuzzy soft sets (FSSs), such as Einstein sum,\r\nEinstein product, algebraic sum, algebraic product, bounded product, bounded sum, and the basic properties of these new\r\noperations have been investigated. In addition, on the basis of our newly defined operations, we implement a new machine\r\nlearning algorithm to solve FSS based real-life decision-making problems (DMPs), and using one real-life example we have\r\ndemonstrated the viability of our proposed approach in real-world applications.\r\n",
        "title": "Some new operations on fuzzy soft sets and their applications in decision-making",
        "authors": [
            "Ajoy Kanti Das",
            "Carlos Granados",
            "Jaydip Bhattacharya"
        ],
        "year": "2022"
    },
    {
        "doi": "10.17392\/1684-23",
        "links": "https:\/\/medicinskiglasnik.ba\/article\/372\/pdf",
        "abstract": "Aim To assess machine-learning models, their methodological quality, compare their performance, and highlight their limitations.\r\nMethods The Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) recommendations were applied. Electronic databases Science Direct, MEDLINE through (PubMed, Google Scholar), EBSCO, ERIC, and CINAHL were searched for the period of January 2016 to September 2023. Using a pre-designed data extraction sheet, the review data were extracted. Big data, risk assessment, colorectal cancer, and artificial intelligence were the main terms.\r\nResults Fifteen studies were included. A total of 3,057,329 colorectal cancer (CRC) health records, including those of adult patients older than 18, were used to generate the results. The curve's area under the curve ranged from 0.704 to 0.976. Logistic regression, random forests, and colon flag were often employed techniques. Overall, these trials provide a considerable and accurate CRC risk prediction.\r\nConclusion An up-to-date summary of recent research on the use of big data in CRC prediction was given. Future research can be facilitated by the review's identification of gaps in the literature. Missing data, a lack of external validation, and the diversity of machine learning algorithms are the current obstacles. Despite having a sound mathematical definition, area under the curve application depends on the modelling context. ",
        "title": "A systematic evaluation of big data-driven colorectal cancer studies",
        "authors": [
            "Eslam Bani Mohammad",
            "Muayyad Ahmad"
        ],
        "year": "2024"
    },
    {
        "doi": "10.22133\/ijwr.2023.396115.1151",
        "links": "https:\/\/ijwr.usc.ac.ir\/article_180790_b39a3945543ac836d998e798db4f3c36.pdf",
        "abstract": "Accurate traffic classification is important for various network activities such as accurate network management and proper resource utilization. Port-based approaches, deep packet inspection, and machine learning are widely used techniques for classifying and analyzing network traffic flows. Most classification methods are suitable for small-scale datasets and cannot achieve a high classification accuracy owing to their shallow learning structure and limited learning ability. The emergence of deep learning technology and software-driven networks has enabled the application of classification methods for processing large-scale data.\r\nIn this study, a two-step classification method based on deep learning algorithms is presented, which can achieve high classification accuracy without manually selecting and extracting features. In the proposed method, an Autoencoder was used to extract features and remove unnecessary and redundant features. In the second step, the proposed method uses the features extracted by the autoencoder from a hybrid deep-learning model based on the CNN and LSTM algorithms to classify network traffic.\r\nTo evaluate the proposed method, the results of the proposed two-stage hybrid method is compared with comparative algorithms including decision tree, Na\u00efve Bayes, random forest. The proposed combined CNN+LSTM method obtains the best results by obtaining values of 0.997, 0.972, 0.959, and 0.964, respectively, for the evaluation criteria of, accuracy, precision, recall, and F1 score.\r\nThe proposed method is a practical and operational method with high accuracy, which can be applied in the real world and used in the detection of security anomalies in networks using traffic classification and network data.",
        "title": "Evaluating Security Anomalies by Classifying Traffic Using a Multi-Layered Model",
        "authors": [
            "Mohammadreza Samadzadeh",
            "Najmeh Farajipour Ghohroud"
        ],
        "year": "2023"
    },
    {
        "doi": "10.1590\/0370-44672023770096",
        "links": "http:\/\/www.scielo.br\/scielo.php?script=sci_arttext&pid=S2448-167X2024000300500&lng=en&tlng=en",
        "abstract": "Abstract In the past decade, machine learning techniques were responsible for a revolution in classification and regression tasks, making it possible to automate some laborious activities, saving time and reducing errors. It is known that the geological logging process is one of the most time-consuming activities accomplished by mining companies. Additionally, it is a subjective activity, and changes in the staff directly affect the geological databases due to different human log interpretation. By developing an automatic log classifier, a company can avoid problems related to the turnover of the staff by standardizing the criteria used to label an interval and can save time by avoiding manual log description. The proposed solution is: given the well log data containing the coordinates, resistivity and natural gamma, the model will be able to predict the presence or absence of coal, and its lithology. The innovation of the methodology proposed, considers not only the geophysical logging values, but additionally inserts the neighbourhood of a given depth as valuable input information, using Fully Convolutional Network. It performs a semantic segmentation using the well log data, which means that model\u00b4s input is the complete well log data curve and the trained model will return an output curve giving the probability of the presence of coal, by interval. The results showed good prediction for the binary problem (F1-score 0.79). The multi-class modelling suffers from the lack of data for each class, resulting in a F1-score from 0.38 for the worst result to 0.76 for the best.",
        "title": "Lithology identification using semantic segmentation for well log data",
        "authors": [
            "\u00c1ttila Le\u00e3es Rodrigues",
            "Fernanda Gontijo Fernandes Niquini",
            "Sandro Pinzon",
            "Jo\u00e3o Felipe Coimbra Leite Costa"
        ],
        "year": "2024"
    },
    {
        "doi": "https:\/\/doi.org\/10.33889\/IJMEMS.2024.9.4.050",
        "links": "https:\/\/www.ijmems.in\/cms\/storage\/app\/public\/uploads\/volumes\/50-IJMEMS-23-0650-9-4-943-964-2024.pdf",
        "abstract": "The agriculture industry has an enormous influence on a nation's economy. Loss of yield due to plant diseases remains a reason, reducing crop quantity and quality. Incorrect diagnosis of crop diseases can result in improper application of chemical pesticides, which promotes immune microbial strains, raises expenses, and triggers fresh outbreaks that are harmful to the economy and the ecosystem. Despite the potential of Machine Learning (ML) and Deep Learning (DL) approaches in plant disease detection, their limited effectiveness results in poor or late disease detection. Resolving this issue is critical, requiring the development of more accurate disease detection methods. This research introduces an innovative approach for the detection of apple leaf diseases utilizing the CNN-based Inception-v3 model. The dataset comprises images taken on location without having any control over the image-capturing settings may provide better relevance to real-world scenarios. The proposed method integrates canny edge detection and watershed transformation to achieve accurate image segmentation, thereby enhancing the identification of disease regions. Additionally, exploratory data analysis was performed, and channel distributions were visualized to understand the dataset's characteristics. To ensure robust evaluation, the model's performance underwent stratified 5-fold cross-validation. The model classified plant images with 84.60% precision, 87.40% recall, 85.00% F1-score, and 94.76% accuracy. Experimental results substantiate the efficacy of the proposed approach, surpassing existing methods in disease classification.",
        "title": "Enhancing Apple Leaf Disease Detection: A CNN-based Model Integrated with Image Segmentation Techniques for Precision Agriculture",
        "authors": [
            "Nidhi Parashar",
            "Prashant Johri"
        ],
        "year": "2024"
    },
    {
        "doi": "10.47473\/2020rmm0071",
        "links": "https:\/\/www.aifirm.it\/wp-content\/uploads\/2021\/04\/RMM-2020-03-Excerpt-1.pdf",
        "abstract": "We compare statistical models usually employed in credit risk forecasting with machine learning algorithms (ML). Using a large \r\ndataset which includes financial ratios and credit behavioral indicators for about 300,000 Italian non-financial firms from 2011 to 2017, we show that training the models on financial statement data only, ML models record a significant improvement in discriminatory power and precision with respect to statistical models; however, this improvement is less pronounced when we enlarge the training dataset to include also credit behavioral data.",
        "title": "Corporate Default Forecasting with Machine Learning",
        "authors": [
            "Mirko Moscatelli",
            "Simone Narizzano",
            "Fabio Parlapiano",
            "Gianluca  Viggiano"
        ],
        "year": "2020"
    },
    {
        "doi": "10.7860\/JCDR\/2020\/43331.13535",
        "links": "https:\/\/jcdr.net\/articles\/PDF\/13535\/43331_F(KM)_CE[Ra1]_KM_PF1(AJ_KM)_PN(SL).pdf",
        "abstract": "The usage of Information, Communication and Technology (ICT) in health sector has a great potential in improving the health of individuals and communities, disease detection, prevention and overall strengthening the healthcare systems, vital for development and poverty reduction. Large ICT establishments offer a variety of Artificial Intelligence (AI) based solutions; and their tenacities are inclusive of wearable therapeutic devices, healthcare management arrangements, extrapolative healthcare diagnostics, ailment prevention systems, detection and screening of diseases and automated tactics. In the field of healthcare related instrumentation, AI plays a prevalent role with the amalgamation of several technological progressions. This enables machines to sense, comprehend, act and learn to perform organisational and clinical healthcare functions as well as serves the research and training purposes. Additionally, it enables to accomplish the anticipated directorial and medicinal benefits. The major causes of life threats reported in literature are; heart and brain diseases. In this paper, an extensive review is presented exploring the evolving ICT technologies in machine learning and AI to help ICT enthusiasts to be able to catch up with the emerging trends in healthcare.",
        "title": "Recent Development in Disease Diagnosis by Information, Communication and Technology",
        "authors": [
            "Shabana Urooj",
            "Astha Sharma",
            "Chitransh Sinha",
            "Fadwa Alrowais"
        ],
        "year": "2020"
    },
    {
        "doi": "10.1590\/1516-4446-2019-0741",
        "links": "http:\/\/www.scielo.br\/scielo.php?script=sci_arttext&pid=S1516-44462020000400014&tlng=en",
        "abstract": "Current first-line treatments for major depressive disorder (MDD) include pharmacotherapy and cognitive-behavioral therapy. However, one-third of depressed patients do not achieve remission after multiple medication trials, and psychotherapy can be costly and time-consuming. Although non-implantable neuromodulation (NIN) techniques such as transcranial magnetic stimulation, transcranial direct current stimulation, electroconvulsive therapy, and magnetic seizure therapy are gaining momentum for treating MDD, the efficacy of non-convulsive techniques is still modest, whereas use of convulsive modalities is limited by their cognitive side effects. In this context, we propose that NIN techniques could benefit from a precision-oriented approach. In this review, we discuss the challenges and opportunities in implementing such a framework, focusing on enhancing NIN effects via a combination of individualized cognitive interventions, using closed-loop approaches, identifying multimodal biomarkers, using computer electric field modeling to guide targeting and quantify dosage, and using machine learning algorithms to integrate data collected at multiple biological levels and identify clinical responders. Though promising, this framework is currently limited, as previous studies have employed small samples and did not sufficiently explore pathophysiological mechanisms associated with NIN response and side effects. Moreover, cost-effectiveness analyses have not been performed. Nevertheless, further advancements in clinical trials of NIN could shift the field toward a more \u201cprecision-oriented\u201d practice.",
        "title": "Precision non-implantable neuromodulation therapies: a perspective for the depressed brain",
        "authors": [
            "Lucas Borrione",
            "Helena Bellini",
            "Lais Boralli Razza",
            "Ana G. Avila",
            "Chris Baeken",
            "Anna-Katharine Brem",
            "Geraldo Busatto",
            "Andre F. Carvalho",
            "Adam Chekroud",
            "Zafiris J. Daskalakis",
            "Zhi-De Deng",
            "Jonathan Downar",
            "Wagner Gattaz",
            "Colleen Loo",
            "Paulo A. Lotufo",
            "Maria da Gra\u00e7a M. Martin",
            "Shawn M. McClintock",
            "Jacinta O\u2019Shea",
            "Frank Padberg",
            "Ives C. Passos",
            "Giovanni A. Salum",
            "Marie-Anne Vanderhasselt",
            "Renerio Fraguas",
            "Isabela Bense\u00f1or",
            "Leandro Valiengo",
            "Andre R. Brunoni"
        ],
        "year": "2020"
    },
    {
        "doi": "10.24874\/PES.SI.24.03.009",
        "links": "https:\/\/pesjournal.net\/journal\/v6-n4\/33.pdf",
        "abstract": "Erythemato-squamous diseases (ESDs), also known as erythrodermas, are a group of dermatological disorders characterized by both redness (erythema) and scaling (squamous) of the skin. These conditions can have various causes and implications. The implications of ESDs vary depending on the specific condition and its severity. While some may cause mild symptoms and have minimal impact on daily life, others can be chronic, recurrent, and significantly affect a person's physical and emotional well-being. Treatment options for these conditions may include topical medications, oral medications, phototherapy, and lifestyle modifications. In this paper, state of art machine learning (ML) algorithms is implemented for classification of ESD. To classify the disease a set of 11 clinical features and 23 histopathological features are considered. The performance of the ML classifiers is analyzed with individual sets of features and combination of both. Further, the performance of the ML classifiers is analyzed at different training rates to know the superior classifier for ESD classification. Furthermore, the study is extended to investigate the effectiveness of the Kruskal-Wallis algorithm in ranking the importance of features in the dataset used for disease classification. An investigation depicts that Ensemble and SVM classifiers outperformed the other ML classifiers in terms of accuracy and F1-score.",
        "title": "MACHINE LEARNING ALGORITHMS FOR ERYTHEMATO-SQUAMOUS DISEASE CLASSIFICATION: FEATURE RANKINGS AND PERFORMANCE ANALYSIS",
        "authors": [
            "M. Venkata Subbarao ",
            "S. Lakshmi Praveena ",
            "T. Naga Sharmila ",
            "Praveen Kumar Nalli ",
            "G. Challa Ram ",
            "D. Ramesh Varma ",
            "Srinivasarao Alluri ",
            "Tabassum Nazeer Syed "
        ],
        "year": "2024"
    },
    {
        "doi": "10.26480\/aim.01.2023.01.07",
        "links": "https:\/\/actainformaticamalaysia.com\/archives\/AIM\/1aim2023\/1aim2023-01-07.pdf",
        "abstract": "Skin cancer is a severe problem that is frequently disregarded. In circumstances of manual examination by a clinician, the human eye is occasionally unable to detect disorders precisely from imaging data. Deep learning techniques are increasingly being used nowadays to solve various problems in our daily lives. Therefore, deep neural network techniques are used to create an automated and computerized mechanism for detecting skin illnesses. To identify and diagnose skin illnesses over a range of criteria several neural network algorithms are evaluated and tested in the suggested model to see how well they perform. The networks are constructed to provide better outcomes using the CNN (Convolution neural network) and the Keras Sequential API architectures. The paper also compares the outcomes of the models using several metrics, such as accuracy, precision, f1 score, and recall. The transfer learning model involves seven models like DenseNet201, InseptionResnetV2, MobileNetV2, InceptionV3, ResNet50, DenseNet169, and VGG16. Among the employed models, the DenseNet169 model achieved the highest score of 87.58% in terms of accuracy; also, in terms of sensitivity and F1 score, DenseNet201 achieved the highest scores of 95.28% and 89.09%, respectively. On the other hand, VGG16 gained a score of 89.67% in terms of specificity, and DenseNet169 achieved the highest score of 90.64% in terms of precision.",
        "title": "TRANSFER LEARNING MODELS COMPARISON FOR DETECTING AND DIAGNOSING SKIN CANCER",
        "authors": [
            "Peshraw Ahmed Abdalla",
            "Abdalbasit Mohammed Qadir",
            "Omed Jamal Rashid",
            "Sarkhel H. Taher Karim",
            "Bashdar Abdalrahman Mohammed",
            "Karzan Jaza Ghafoor"
        ],
        "year": "2022"
    },
    {
        "doi": "http:\/\/dx.doi.org\/10.30595\/techno.v24i2.19267",
        "links": "https:\/\/jurnalnasional.ump.ac.id\/index.php\/Techno\/article\/view\/19267\/pdf",
        "abstract": "Pendemi Covid-19 pernah terjadi di akhir tahun 2019, walau pandemi sudah berlalu untuk usaha pencegahan kasus yang sama maka pengecekan suhu tubuh dan masker masih diberlakukan terutama ditempat publik misalnya di kantor perbankan, tempat ibadah, sekolah dan sebagainya dan kenyataanya virus dapat bermutasi dan pernah ditemukan variannya. Penelitian ini merupakan penelitian lanjutan dari penulis tentang deteksi masker dengan menambahkan fitur pengecekan suhu tubuh untuk kontrol otomatis sistem buka tutup portal. Implementasi sistem dilakukan di mesin android model hasil pelatihan deteksi masker dilatih menggunakan machine learning dan deteksi suhu menggunakan sensor non kontak MLX90614. Berdasarkan pengujian sistem telah bekerja dengan baik, portal akan membuka secara otomatis jika pengunjung menggunakan masker dan suhu tubuh dibawah 37,5 oC. Dari 20 kali pengujian seseorang yang memakai masker dan tidak makai master serta suhu norma dan non normal sistem memiliki keberhasilan 98%.",
        "title": "Deteksi Suhu Tubuh dan Masker untuk Kendali Portal Otomatis Menggunakan Machine Learning",
        "authors": [
            "Arif Johar Taufiq,",
            "Tito Pinandita,",
            "Susiyadi,",
            "Juanita"
        ],
        "year": "2023"
    },
    {
        "doi": "10.24818\/jamis.2022.04001",
        "links": "http:\/\/online-cig.ase.ro\/jcig\/art\/21_4_1.pdf",
        "abstract": "Research Question: Do external auditors in the United Arab Emirates (UAE) perceive the ease of use and usefulness of Machine Learning (ML)?\r\nMotivation: This study aims to investigate external auditors' perceptions of the ease of use and usefulness of Machine Learning in auditing in the UAE. In addition, the study intends to examine the difference in perceived ease of use of Machine Learning between local and international audit companies in the UAE.\r\nData: Data for this study were gathered from 63 external auditors working for local and global audit firms in the UAE. The study's population comprises external auditors from national and international audit companies in UAE.\r\nTool: The questionnaire was deployed through an online survey tool.\r\nFindings: The results have shown that the findings do not support the idea that there is a different perception of the Perceived Ease of Use of Machine Learning in auditing between local and international audit firms. According to the conclusions of this study, external auditors have a restricted perception of the simplicity of use and utility of Machine Learning.\r\nPractical implications: The importance of the findings of such research stems from the lack of research evidence on the perceived ease of use and usefulness of Machine Learning in external auditing in the UAE. As a result, this paper provides new empirical evidence by assessing external auditors' assessments of the usage of Machine Learning in the UAE. \r\n",
        "title": "Machine learning and external auditor perception: An analysis for UAE external auditors using technology acceptance model",
        "authors": [
            "Ahmad Faisal Hayek",
            "Nora Azima Noordin",
            "Khaled Hussainey"
        ],
        "year": "2022"
    },
    {
        "doi": "10.22521\/edupij.2022.112.7",
        "links": "https:\/\/www.edupij.com\/files\/1\/articles\/article_258\/EDUPIJ_258_article_62ba3e55e6c41.pdf",
        "abstract": "Background\/purpose \u2013 During the COVID-19 pandemic, teachers were required to update school activities using various technological tools. The aim of this mixed research was the construction and usage analysis of the Digital Game for the teaching-learning process on Electronics (DGE) version 3.0 in the Combinational Circuits unit through data science.\r\n\r\nMaterials\/methods \u2013 DGE version 3.0 facilitates the construction of new educational spaces in the distance modality. This web game consists of a simulator that presents the contents of the output function for two variables and their representation through logic gates. The participants of the study were 15 electronic and electrical engineering students who took a digital design course at the National Autonomous University of Mexico during the 2021 academic year.\r\n\r\nResults \u2013 The machine learning (linear regression) results indicate that the interface, design, and color of the DGE version 3.0 web game positively influenced the students\u2019 assimilation of knowledge and skills development in the field of electronics. On the other hand, the decision tree technique identified six predictive models with regards to the use of the DGE version 3.0.\r\n\r\nConclusion \u2013 Technological advances such as web gaming can facilitate the teaching-learning process from virtually any location.",
        "title": "Construction of a Web Game for the Teaching-Learning Process of Electronics during the COVID-19 Pandemic",
        "authors": [
            "Ricardo-Ad\u00e1n Salas-Rueda, Clara Alvarado-Zamorano, Jes\u00fas Ram\u00edrez-Ortega"
        ],
        "year": "2022"
    },
    {
        "doi": "10.3350\/cmh.2023.0287",
        "links": "http:\/\/e-cmh.org\/upload\/pdf\/cmh-2023-0287.pdf",
        "abstract": "Background\/Aims Despite the high efficacy of direct-acting antivirals (DAAs), approximately 1\u20133% of hepatitis C virus (HCV) patients fail to achieve a sustained virological response. We conducted a nationwide study to investigate risk factors associated with DAA treatment failure. Machine-learning algorithms have been applied to discriminate subjects who may fail to respond to DAA therapy. Methods We analyzed the Taiwan HCV Registry Program database to explore predictors of DAA failure in HCV patients. Fifty-five host and virological features were assessed using multivariate logistic regression, decision tree, random forest, eXtreme Gradient Boosting (XGBoost), and artificial neural network. The primary outcome was undetectable HCV RNA at 12 weeks after the end of treatment. Results The training (n=23,955) and validation (n=10,346) datasets had similar baseline demographics, with an overall DAA failure rate of 1.6% (n=538). Multivariate logistic regression analysis revealed that liver cirrhosis, hepatocellular carcinoma, poor DAA adherence, and higher hemoglobin A1c were significantly associated with virological failure. XGBoost outperformed the other algorithms and logistic regression models, with an area under the receiver operating characteristic curve of 1.000 in the training dataset and 0.803 in the validation dataset. The top five predictors of treatment failure were HCV RNA, body mass index, \u03b1-fetoprotein, platelets, and FIB-4 index. The accuracy, sensitivity, specificity, positive predictive value, and negative predictive value of the XGBoost model (cutoff value=0.5) were 99.5%, 69.7%, 99.9%, 97.4%, and 99.5%, respectively, for the entire dataset. Conclusions Machine learning algorithms effectively provide risk stratification for DAA failure and additional information on the factors associated with DAA failure.",
        "title": "Artificial intelligence predicts direct-acting antivirals failure among hepatitis C virus patients: A nationwide hepatitis C virus registry program",
        "authors": [
            "Ming-Ying Lu",
            "Chung-Feng Huang",
            "Chao-Hung Hung",
            "Chi\u2010Ming Tai",
            "Lein-Ray Mo",
            "Hsing-Tao Kuo",
            "Kuo-Chih Tseng",
            "Ching-Chu Lo",
            "Ming-Jong Bair",
            "Szu-Jen Wang",
            "Jee-Fu Huang",
            "Ming-Lun Yeh",
            "Chun-Ting Chen",
            "Ming-Chang Tsai",
            "Chien-Wei Huang",
            "Pei-Lun Lee",
            "Tzeng-Hue Yang",
            "Yi-Hsiang Huang",
            "Lee-Won Chong",
            "Chien-Lin Chen",
            "Chi-Chieh Yang",
            "Sheng\u2010Shun Yang",
            "Pin-Nan Cheng",
            "Tsai-Yuan Hsieh",
            "Jui-Ting Hu",
            "Wen-Chih Wu",
            "Chien-Yu Cheng",
            "Guei-Ying Chen",
            "Guo-Xiong Zhou",
            "Wei-Lun Tsai",
            "Chien-Neng Kao",
            "Chih-Lang Lin",
            "Chia-Chi Wang",
            "Ta-Ya Lin",
            "Chih\u2010Lin Lin",
            "Wei-Wen Su",
            "Tzong-Hsi Lee",
            "Te-Sheng Chang",
            "Chun-Jen Liu",
            "Chia-Yen Dai",
            "Jia-Horng Kao",
            "Han-Chieh Lin",
            "Wan-Long Chuang",
            "Cheng-Yuan Peng",
            "Chun-Wei- Tsai",
            "Chi-Yi Chen",
            "Ming-Lung Yu",
            ""
        ],
        "year": "2024"
    },
    {
        "doi": "10.52254\/1857-0070.2022.3-55.08",
        "links": "https:\/\/journal.ie.asm.md\/assets\/files\/08_03_55_2022.pdf",
        "abstract": "Energy prices and \u0441ost of materials for solar and wind power plants have increased over the past year. Therefore, significance increases for the hydropower and long-term (1\u201310 years) planning generation for the existing hydropower plants, which requires forecasting the average monthly values of the river flow. This task is especially urgent for countries without their own oil-fields and opportunity to invest in the creation of solar or wind power plants. The aim of the research is to decrease the mean absolute forecasting error of the long-term prediction for the Vakhsh River flow (Tajikistan) based on the long-term observations. A study of existing methods for the river runoff forecasting in relation to the object under consideration was carried out, and a new transformation model for the space of the input features was developed. The most significant results are the decrease in the average forecast error in the Vakhsh river flow achieved by the use of the proposed space of polynomial logarithmic features in comparison with other methods, and the need to use at least the 20 year-old observational data for the long-term operation plan-ning of the hydropower plants and cascades of the hydropower plants obtained from the results of computational experiments. The significance of the results lies in the fact that a new approach to the long-term forecasting of river flow has been proposed and verified using the long-term observations. This approach does not require the use of the long-term meteorological forecasts, which are not possible to obtain with high accuracy for all regions.",
        "title": "Monthly Runoff Forecasting by Non-Generalizing Machine Learning Model and Feature Space Transformation (Vakhsh River Case Study)",
        "authors": [
            "Matrenin P.V.",
            "Safaraliev M.K.",
            "Kiryanova N.G.",
            "Sultonov S.M."
        ],
        "year": "2022"
    },
    {
        "doi": "10.30892\/gtg.53214-1226",
        "links": "https:\/\/gtg.webhost.uoradea.ro\/PDF\/GTG-2-2024\/gtg.53214-1226.pdf",
        "abstract": "This article aims to systematically investigate and elucidate the transformative effects of Artificial Intelligence (AI)\r\nand Machine Learning (ML) on marketing strategies and consumer engagement within the tourism and hospitality industries.\r\nThe research methodology employed in this article encompasses a quantitative approach, underpinned by the use of cluster\r\nanalysis to categorize and interpret complex multivariate data. This methodological framework is chosen to provide a\r\nrigorous, data-driven examination of the impacts of Artificial Intelligence (AI) and Machine Learning (ML) on marketing\r\nstrategies and consumer behavior in the tourism and hospitality industry. The results of this investigation reveal significan t\r\ninsights into the application of Artificial Intelligence (AI) and Machine Learning (ML) in enhancing marketing strategies\r\nwithin the tourism and hospitality sectors. Through the application of the k-means clustering algorithm to the collected\r\ndataset, distinct patterns of consumer behavior and preferences have emerged, underscoring the potential of AI and ML to\r\nrevolutionize marketing approaches and consumer engagement. The findings from this research underscore the pivotal role of\r\nArtificial Intelligence (AI) and Machine Learning (ML) in transforming marketing strategies and enhancing consumer\r\nengagement within the tourism and hospitality industries. The utilization of cluster analysis, specifically the k -means\r\nalgorithm, has facilitated a deeper understanding of consumer behavior patterns, leading to several key conclusions.",
        "title": "REDEFINING CONSUMER ENGAGEMENT: THE IMPACT OF AI AND MACHINE LEARNING ON MARKETING STRATEGIES IN TOURISM AND HOSPITALITY",
        "authors": [
            "Maria Nascimento CUNHA",
            "Manuel PEREIRA",
            "Ant\u00f3nio CARDOSO ",
            "Jorge FIGUEIREDO",
            "Isabel OLIVEIRA "
        ],
        "year": "2024"
    },
    {
        "doi": "10.1590\/0370-44672023760002",
        "links": "http:\/\/www.scielo.br\/scielo.php?script=sci_arttext&pid=S2448-167X2023000400329&lng=en&tlng=en",
        "abstract": "Abstract Among several works, constructions in rock masses are the most complex in engineering, due to many uncertainties of the environment. Tunnel construction is a case in point. A common problem found in tunnel excavations with the use of explosives is the occurrence of overbreak beyond the boundary line of the tunnel. Many researchers worldwide have proposed forecasting techniques based on the use of regression models or machine learning, however, these require many samples and variables, such as the explosive rate and rock mass. Predicting overbreak before blasting is essential in project management, as it can modify parameters of the blasting plan, design, schedule and employee safety. Therefore, this study sought to employ an exponential smoothing model, which could predict the percentage (%) of overbreak in a tunnel section, based solely on the previous overbreak values. This time series methodology has never been used before in tunnel excavations, although it is used in the financial market. The technique was tested in one Brazilian tunnel. The model proved to be very efficient in predicting overbreak in tunnel construction, since it can be adjusted at each advance. The model can be adjusted as a function of \u03b1: where \u03b1 is close to zero, the model prioritizes past events, while for \u03b1 close to 1, it prioritizes recent events. The best fit occurred with \u03b1 = 0.9; 0<\u03b1<1.",
        "title": "Overbreak prediction of tunnels carved in rock mass through exponential smoothing: case study of tunnel in Brazil",
        "authors": [
            "F\u00e1bio Jos\u00e9 Generoso",
            "Andr\u00e9 Cezar Zingano",
            "Irce Fernandes Gomes Guimar\u00e3es",
            "Rog\u00e9rio Aguirre Dias"
        ],
        "year": "2023"
    },
    {
        "doi": "10.3897\/rio.3.e11731",
        "links": "https:\/\/riojournal.com\/article\/11731\/",
        "abstract": "Cerebral aneurysm is a cerebrovascular disorder characterized by a bulging in a weak area in the wall of an artery that supplies blood to the brain. It is relevant to understand the mechanisms leading to the apparition of aneurysms, their growth and, more important, leading to their rupture. The purpose of this study is to study the impact on aneurysm rupture of the combination of different parameters, instead of focusing on only one factor at a time as is frequently found in the literature, using machine learning and feature extraction techniques. This discussion takes relevance in the context of the complex decision that the physicians have to take to decide which therapy to apply, as each intervention bares its own risks, and implies to use a complex ensemble of resources (human resources, OR, etc.) in hospitals always under very high work load.\n  This project has been raised in our actual working team, composed of interventional neuroradiologist, radiologic technologist, informatics engineers and biomedical engineers, from Valparaiso public Hospital, Hospital Carlos van Buren, and from Universidad de Valparai\u0301so \u2013 Facultad de Ingenieri\u0301a and Facultad de Medicina. This team has been working together in the last few years, and is now participating in the implementation of an \u201cinterdisciplinary platform for innovation in health\u201d, as part of a bigger project leaded by Universidad de Valparaiso (PMI UVA1402). It is relevant to emphasize that this project is made feasible by the existence of this network between physicians and engineers, and by the existence of data already registered in an orderly manner, structured and recorded in digital format.\n  The present proposal arises from the description in nowadays literature that the actual indicators, whether based on morphological description of the aneurysm, or based on characterization of biomechanical factor or others, these indicators were shown not to provide sufficient information in order to predict by themselves the risk of rupture. Therefore, our hypothesis is that the risk of rupture lies on the combination of multiple actors. These actors together would play different roles that could be: weakening of the artery wall, increasing biomechanical stresses on the wall induced by blood flow, in addition to personal sensitivity due to family history, or personal history of comorbidity, or even seasonal variations that could gate different inflammation mechanisms.\n  The main goal of this project is to identify relevant variables that may help in the process of predicting the risk of intracranial aneurysm rupture using machine learning and image processing techniques based on structured and non-structured data from multiple sources. We believe that the identification and the combined use of relevant variables extracted from clinical, demographical, environmental and medical imaging data sources will improve the estimation of the aneurysm rupture risk, with respect to the actual practiced method based essentially on the aneurysm size.\n  The methodology of this work consist of four phases: (1) Data collection and storage, (2) feature extraction from multiple sources in particular from angiographic images, (3) development of the model that could describe the risk of aneurysm rupture based on the fusion and combination of the features, and (4) Identification of relevant variables related to the aneurysm rupture process. This study corresponds to an analytic transversal study with prospective and retrospective characteristics. This work will be based on publicly available health statistics data, data of weather conditions, together with clinical and demographic data of patients diagnosed with intracranial aneurysm in the Hospital Carlos van Buren.\n  As main results of this project we are expecting to identify relevant variables extracted from images and other sources that could play a role in the risk of aneurysm rupture. The proposed model will be presented to the physicians of the Hospital Carlos van Buren, to be further implemented in this Institution according to the demonstrated impact of our results. The main results will be published in indexed journals and presented at national and international conferences.",
        "title": "Applying machine learning and image feature extraction techniques to the problem of cerebral aneurysm rupture",
        "authors": [
            "Steren Chabert",
            "Tom\u00e1s Mardones",
            "Rodrigo Riveros",
            "Maximiliano Godoy",
            "Alejandro Veloz",
            "Rodrigo Salas",
            "Pablo Cox"
        ],
        "year": "2017"
    },
    {
        "doi": "10.1590\/0100-6991e-20233561-en",
        "links": "http:\/\/www.scielo.br\/scielo.php?script=sci_arttext&pid=S0100-69912023000100228&lng=en&tlng=en",
        "abstract": "ABSTRACT  Introduction:  flexible ureteroscopy is a minimally invasive surgical technique used for the treatment of renal lithiasis. Postoperative urosepsis is a rare but potentially fatal complication. Traditional models used to predict the risk of this condition have limited accuracy, while models based on artificial intelligence are more promising. The objective of this study is to carry out a systematic review regarding the use of artificial intelligence to detect the risk of sepsis in patients with renal lithiasis undergoing flexible ureteroscopy.  Methods:  the literature review is in accordance with the Preferred Reporting Items for Systematic Reviews and Meta-Analysis (PRISMA). The keyword search was performed in MEDLINE, Embase, Web of Science and Scopus and resulted in a total of 2,496 articles, of which 2 met the inclusion criteria.  Results:  both studies used artificial intelligence models to predict the risk of sepsis after flexible uteroscopy. The first had a sample of 114 patients and was based on clinical and laboratory parameters. The second had an initial sample of 132 patients and was based on preoperative computed tomography images. Both obtained good measurements of Area Under the Curve (AUC), sensitivity and specificity, demonstrating good performance.  Conclusion:  artificial intelligence provides multiple effective strategies for sepsis risk stratification in patients undergoing urological procedures for renal lithiasis, although further studies are needed.",
        "title": "Use of artificial intelligence for sepsis risk prediction after flexible ureteroscopy: a systematic review",
        "authors": [
            "BEATRIZ MESALIRA ALVES",
            "MIKHAEL BELKOVSKY",
            "CARLO CAMARGO PASSEROTTI",
            "EVERSON LUIZ DE ALMEIDA ARTIFON",
            "JOS\u00c9 PINHATA OTOCH",
            "JOS\u00c9 ARNALDO SHIOMI DA CRUZ"
        ],
        "year": "2023"
    },
    {
        "doi": "10.1590\/1678-4324-2023220556",
        "links": "http:\/\/www.scielo.br\/scielo.php?script=sci_arttext&pid=S1516-89132023000100621&lng=en&tlng=en",
        "abstract": "Abstract The presented development is an intelligent diagnostic system for transformers that studied machine learning techniques to determine the operational status of these transformers. The study of these techniques is initiated by observing the quantities that define the operational behavior of large transformers, aiming to identify anomalies in their operation from data from sensors that equipment it in the functioning environment. This large power transformer has a theoretical service life of above 20 years and a low failure rate. Thus, obtaining failure values, which have their evolution monitored for large transformers, is almost nil. Therefore, a supervised machine training methodology to diagnose these cases is practically unfeasible. The study carried out with several traditional intelligent techniques can verify this. Several supervised methods (Closest Neighbor K-th Neighbor, Support Vector Machine, Radial Base Function, Decision Trees, Random Forest, Neural Network, AdaBoost, Gaussian Naive Bayes, and Quadratic Discriminant Analysis) were studied.",
        "title": "Studying Intelligent Techniques Acting in Large Power Transformer Monitoring",
        "authors": [
            "Elvis Ricardo de Oliveira",
            "Vanias de Araujo Junior",
            "Jos\u00e9 Faustino da Silva C\u00e2ndido",
            "Germano Lambert-Torres",
            "Luiz Eduardo Borges da Silva",
            "Erik Leandro Bonaldi",
            "Gilberto Capistrano Cunha de Andrade",
            "Levy Ely de Lacerda de Oliveira",
            "Carlos Henrique Val\u00e9rio de Moraes",
            "Carlos Eduardo Teixeira"
        ],
        "year": "2023"
    },
    {
        "doi": "10.25206\/1813-8225-2018-160-67-72",
        "links": "https:\/\/www.omgtu.ru\/general_information\/media_omgtu\/journal_of_omsk_research_journal\/files\/arhiv\/2018\/4%20(160)\/67-72%20%D0%91%D0%BE%D1%80%D0%B8%D1%81%D0%B5%D0%BD%D0%BA%D0%BE%20%D0%94.%20%D0%92.,%20%D0%9F%D1%80%D0%B8%D1%81%D1%83%D1%85%D0%B8%D0%BD%D0%B0%20%D0%98.%20%D0%92.,%20%D0%9B%D1%83%D0%BD%D1%91%D0%B2%20%D0%A1.%20%D0%90..pdf",
        "abstract": "Electric track circuits are widely used on railways as sensors\r\nproviding position of a train and information about physical\r\nintegrity of rails. A modern railway monitoring system is required\r\nto have automatic data analysis capabilities. For a track circuit this\r\nfunctionality can be implemented as automatic state classification.\r\nTo perform this task, we developed an algorithm based on logistic\r\nregression. In this article we describe basic principles of the\r\nalgorithm and machine learning techniques that are applied.",
        "title": "Machine state classification of electric track circuit by means of logistic regression",
        "authors": [
            "D. V. Borisenko",
            " I. V. Prisukhina",
            "S. A. Lunev"
        ],
        "year": "2018"
    },
    {
        "doi": "10.32983\/2222-4459-2023-9-255-262",
        "links": "https:\/\/www.business-inform.net\/export_pdf\/business-inform-2023-9_0-pages-255_262.pdf",
        "abstract": "The aim of the article is to determine the contextual and temporal regularities of the development of the presentation in the scientific literature of research in the field of project risk management using bibliometric analysis. To achieve this aim, this study analyzed the following: the trend and structural patterns of publication activity of scholars around the world; the geographical structure of affiliation of scientists; the topics of the most cited articles on project risk management, also a bibliometric analysis using the instrumentarium of VOSviewer v. 1.6.10 as the research tools for analyzing relevant literature from the Scopus database on project risk management. A bibliometric analysis with the central category of \u00abproject risk\u00bb made it possible to identify eight clusters of scientific research on project risk management: the first cluster is focused on risk management methodology, investment and innovation risk, development and implementation of an innovative product, startup; the second \u2013 on project risk management in the field of information technology, information systems, software, identification of risk factors and evaluation of project efficiency; the third \u2013 on the optimization of risk management, modeling, the use of methods and instruments in the risk management system (hierarchy analysis method, fuzzy logic method); the fourth \u2013 on the assessment of risk probability, cost and complexity of the project; the fifth \u2013 on the assessment of the quality of the project, substantiation of the management strategy; the sixth \u2013 on the peculiarities of the product life cycle, project infrastructure, management of specific project risks (stakeholders, political situation, technology development); the seventh \u2013 on the practical application of standards, algorithms, and models of project risk management; the eighth cluster is based on substantiating the choice of the project, setting risk limits, developing algorithms, and using artificial intelligence. A promising area of management is risk management in the field of information technology, namely: risk management of IT projects and software; development and implementation of startups and innovative products; the use of machine learning and artificial intelligence.",
        "title": "Status and Trends of Research in the Field of Project Risk Management",
        "authors": [
            "Hubarieva Iryna O.",
            "Marushchenko Oleksandr O.",
            "Koss Anton V."
        ],
        "year": "2023"
    },
    {
        "doi": "10.5267\/j.dsl.2020.5.004",
        "links": "http:\/\/www.growingscience.com\/dsl\/Vol9\/dsl_2020_16.pdf",
        "abstract": "",
        "title": "An approach based on machine learning techniques for forecasting Vietnamese consumers\u2019 purchase behaviour",
        "authors": [
            "Quang Hung Do ",
            "Tran Van Trang "
        ],
        "year": "2020"
    },
    {
        "doi": "10.24874\/PES06.04.017",
        "links": "https:\/\/pesjournal.net\/journal\/v6-n4\/17.pdf",
        "abstract": "Machine Learning centers on applications that gain for a fact and further develop their dynamic or prescient exactness over the long run. Behavioral Modification is the use of basic learning techniques such as conditioning, biofeedback, assertiveness training, positive or negative reinforcement, aversion therapy to change unwanted individual or group behavior. Behavior change is vital to addressing both the challenges facing human health and wellbeing and to promoting the uptake of research findings in health policy and practice. This paper provides a solution about the utilization of machine learning in behavioral modification by giving some real-time examples. The device based on machine learning is used to develop and evaluate a \u2018Knowledge System\u2019 that automatically extracts, synthesizes, and interprets findings from Brain Computer Interface (BCI) evaluation reports to generate new insights to conduct change and further develop forecast of intervention viability and permits clients to effectively and productively examine the framework to find solutions. Organizations engaged in healthcare are charged with the complex task of keeping expenses down without compromising healthcare quality. The key prerequisite is to focus instead of fix, with the greatest test being the need to follow up on enormous volumes of totaled medical care driven Big Data.",
        "title": "APPLICATION OF MACHINE LEARNING IN BEHAVIORAL MODIFICATION",
        "authors": [
            "Sudeep Varshney ",
            "Aditi Chandra ",
            "Pushpendra Kumar Rajput ",
            "Sunil Kumar   ",
            "Gunjan Varshney "
        ],
        "year": "2024"
    },
    {
        "doi": "10.1590\/1809-4430-eng.agric.v39n5p639-648\/2019",
        "links": "http:\/\/www.scielo.br\/scielo.php?script=sci_arttext&pid=S0100-69162019000500639&tlng=en",
        "abstract": "ABSTRACT We propose a segmentation algorithm for raisin extraction. The proposed approach consists of the following aspects. Deep learning is used to predict the number of raisins in each connected region, and the shape features such as the roundness, area, X-axis value for the centroid, Y-axis value for the centroid, axis length and perimeter of each region will be used to establish the prediction model. Morphological analysis, based on edge parameters including the polar axis, polar angle and angular velocity, is applied to search for the suitable break points that are useful for identifying the dividing lines between two adjacent raisins. To make our segmentation more accurate, some machine-learning algorithms such as the random forest (RF), support vector machine (SVM) and deep learning (deep neural network, DNN) are applied to predict the number of raisins and to decide whether the raisins need more segmentation. The performance of the three models is compared, and the DNN is the most accurate.",
        "title": "A NOVEL RAISIN SEGMENTATION ALGORITHM BASED ON DEEP LEARNING AND MORPHOLOGICAL ANALYSIS",
        "authors": [
            "Yun Zhao",
            "Mahamed L. Guindo",
            "Xing Xu",
            "Xiang Shi",
            "Miao Sun",
            "Yong He"
        ],
        "year": "2019"
    },
    {
        "doi": "10.11606\/s1518-8787.2024058006161",
        "links": "http:\/\/www.scielo.br\/scielo.php?script=sci_arttext&pid=S0034-89102024000100236&lng=en&tlng=en",
        "abstract": "ABSTRACT  OBJECTIVE: To develop and validate a predictive model utilizing machine-learning techniques for estimating the length of hospital stay among patients who underwent coronary artery bypass grafting.  METHODS: Three machine learning models (random forest, extreme gradient boosting and neural networks) and three traditional regression models (Poisson regression, linear regression, negative binomial regression) were trained in a dataset of 9,584 patients who underwent coronary artery bypass grafting between January 2017 and December 2021. The data were collected from hospital discharges from 133 centers in Brazil. Algorithms were ranked by calculating the root mean squared logarithmic error (RMSLE). The top performing algorithm was validated in a never-before-seen database of 2,627 patients. We also developed a model with the top ten variables to improve usability.  RESULTS: The random forest technique produced the model with the lowest error. The RMLSE was 0.412 (95%CI 0.405\u20130.419) on the training dataset and 0.454 (95%CI 0.441\u20130.468) on the validation dataset. Non-elective surgery, admission to a public hospital, heart failure, and age had the greatest impact on length of hospital stay.  CONCLUSIONS: The predictive model can be used to generate length of hospital stay indices that could be used as markers of efficiency and identify patients with the potential for prolonged hospitalization, helping the institution in managing beds, scheduling surgeries, and allocating resources.",
        "title": "Development of a machine learning model to estimate length of stay in coronary artery bypass grafting",
        "authors": [
            "Renato Camargos Couto",
            "Tania Pedrosa",
            "Luciana Moreira Seara",
            "Vitor Seara Couto",
            "Carolina Seara Couto"
        ],
        "year": "2024"
    },
    {
        "doi": "10.1590\/1413-7054202448016123",
        "links": "http:\/\/www.scielo.br\/scielo.php?script=sci_arttext&pid=S1413-70542024000100227&lng=en&tlng=en",
        "abstract": "ABSTRACT To quickly and accurately assess tea plant growth, this study aims to find a new way to predict the chlorophyll content in tea plant canopies using machine learning. Using remotely piloted aircraft equipped with multispectral cameras, images of tea plantation areas are captured and reflectance from four spectral bands is extracted, leading to the calculation of vegetation indices. Simultaneously, chlorophyll relative content in the tea plant canopies was collected on the ground using a detector. Four models, namely Random Forest (RF), Backpropagation neural network (BPNN), Radial basis function network (RBFN), and General Regression Neural Network (GRNN), were constructed to predict the chlorophyll relative content in tea plant canopies. Subsequently, important remote sensing variables were identified through RF filtering, followed by a comparison of the predictive performance of machine learning models under different input conditions. Lastly, by integrating the Sparrow Search Algorithm (SSA) to optimize the smoothing factor in the GRNN, the study explores the impact of optimization algorithms on the predictive performance of the GRNN model. Experiments indicate that within the established machine learning models, the GRNN demonstrates the highest predictive accuracy. By ranking the importance of remote sensing variables through RF, 18 significant remote sensing variables were selected, which enhanced the predictive accuracy of the machine learning models. The optimization of the GRNN smoothing factor through the SSA algorithm can significantly enhance the predictive accuracy of the GRNN model. Based on a series of experiments, the established RFSSA-GRNN prediction model demonstrates good predictive performance, with an reaching 0.84.",
        "title": "Prediction of chlorophyll relative content in tea plant canopy using optimize GRNN algorithm and RPA multispectral images",
        "authors": [
            "Qingyan Zhou",
            "Jincheng Zhang",
            "Tangwei Wei",
            "Wen Xing",
            "Jing Wang",
            "Youhua Zhang"
        ],
        "year": "2024"
    },
    {
        "doi": "10.22521\/edupij.2023.124.3",
        "links": "https:\/\/www.edupij.com\/files\/1\/articles\/article_311\/EDUPIJ_311_article_654688461e0c7.pdf",
        "abstract": "\r\nBackground\/purpose \u2013The unprecedented developments in AI-based technologies and large language models such as ChatGPT have exhibited a brand-new territory to be explored. Since its first release in November 2022, the potential utility of ChatGPT has garnered incremental attention in the scientific world, and has already accumulated a great number of studies from diverse fields. The current study was conducted with the purpose of exploring the scientific landscape of the evolving knowledge base related to the use of ChatGPT in the field of education and health through science mapping analysis of published research.\r\n\r\nMaterials\/methods \u2013 Data were retrieved from Web of Science and Scopus, and a comparative, period-based science mapping analysis was conducted using the SciMAT software.\r\n\r\nResults \u2013 The results showed that the studies published during the first period mostly focused on machine learning, reproductive medicine, education and first-year undergraduate themes. During the second period, though, the studies featured themes that are closely related to the design and performance of ChatGPT such as large language models (LLMs), natural language processing (NLP) and chatbot while abandoning a focus on artificial intelligence. These results imply that discussions and investigations over ChatGPT were being departed from those in the field of artificial intelligence, and the focus was becoming more central to the features of ChatGPT as a language model that can process huge amounts of information to generate human-like texts. Plagiarism and research ethics were also emerging themes during the last period.\r\n\r\nConclusion \u2013 The results of the science mapping showed a growing interest into the opportunities and risks of ChatGPT, particularly for fields of education and medicine, and indicated that much research is warranted to discover the potential of GPT technology as an uncharted territory.",
        "title": "Assessing the Intellectual Structure of the Evolving Knowledge Base on ChatGPT in the Field of Education and Health",
        "authors": [
            "Murat Demirkol and Nedim Malkoc"
        ],
        "year": "2023"
    },
    {
        "doi": "10.3897\/oneeco.9.e134088",
        "links": "https:\/\/oneecosystem.pensoft.net\/article\/134088\/download\/pdf\/",
        "abstract": "The landscapes in the Hinh River Basin are crucial and highly sensitive to climate change for the coastal province of Phu Yen and the entire south-central coastal region of Vietnam, offering vital environmental services to its downstream areas. Hinh River Basin has a rich system of rivers and streams and abundant surface water resources. However, it remains one of the region&#039;s top localities at risk and a very vulnerable region. This study aims to evaluate the changes in landscape (LC) over 10 years (2010-2023) and predict LC over the next six years using machine-learning (ML) algorithms on Google Earth Engine. To achieve these study goals, we establish: (i) potential environmental fragility (PEF) levels based on: terrain slope; geological domains; river hierarchy; percentage of sand in soil; annual mean precipitations; and (ii) emergent environmental fragility (EEF) levels through the addition of LC parameter to model. The methodology includes integrating the Analytic Hierarchy Process (AHP) into a Geographic Information System (GIS). Results show that three LC types (water, annual industrial crop, forest) are related to extremely high EEF. The predictive model suggests that, by 2030, the forest and annual industrial crop LCs in the study area will increase by around 20%. The analysis results show that there has been an increase in the area of planted forests, which can confirm the futher effectiveness of agricultural, forestry, afforestation and forest protection programmes in the study area (Plan for the implementation of forestry development strategy for the period 2021-2030, with a vision to 2050, Phu Yen Province, No 126\/KH-UBND 13\/7\/2021; and Decision on the approval of the project for planting 15 million trees in Phu Yen Province for the period 2021-2025, No 1646\/Q\u0110-UBND 16\/11\/2021).",
        "title": "Landscape Dynamics and Environmental Fragility Zoning in Hinh River Basin: Insights for protecting natural ecosystems",
        "authors": [
            "Quoc Khanh Nguyen",
            "Hanh Tong",
            "Liem Nguyen",
            "Thu Nga Nguyen",
            "Trung Dung Ngo",
            "Nguyen Hong Quang",
            "Anh Tu Dinh",
            "Mai-Phuong Pham"
        ],
        "year": "2024"
    },
    {
        "doi": "10.59277\/ritl.2024.18.06",
        "links": "https:\/\/ritl.ro\/pdf\/2024\/6_A_Dinu.pdf",
        "abstract": "Digital Humanities (DH) is a scientific domain, albeit an elusive one. Broadly, DH studies digital cultural objects in a computational way. There is no commonly accepted definition. The challenge in defining DH stems from the wide variety of disciplines involved, like cultural heritage, linguistics, literature, digital archaeology, history, arts, philosophy, etc. that all have their own methodology and tools. A common misunderstanding is that the DH is concerned only with the conversion of physical objects like manuscripts, maps, cultural artefacts, sounds, into a machine-readable format. But this is only the first step: ob\u00adtaining the object of study. The most challenging part is the computational processing of the digital objects by operations such as interrogation, editing, annotating, visualization, Data Mining, automatic classification, clustering, pattern recognition, information extraction, etc. Only a decade ago, all of these could have been performed exclusively by scholars with computer science background, but now the tendency is to develop user-friendly tools, or use prompt engineering for large language models, to make it easy for humanists to benefit from these computational analysis methods. In the last half of the decade, we witnessed a fourth industrial revolution, with the fulminating rise of Artificial Intelligence technologies. In this dynamic context, the role of DH scholars increases. Smart, creative, adaptive, and visionary digital humanists are needed to use AI systems to benefit people. In short, we need digital literacy on a large scale and adapting to continuous learning. An example of such good practice is the array of dissertation topics proposed by students graduating the Digital Humanities master Program at FLLS, like the computational analysis of the discourses of the last four Romanian presidents, the automatic detection and classification of mental illnesses from social media posts, the diachronic analysis of semantic shift of gender representation in corpora, the comparative semi-automatic analysis of literary cur\u00adrents, the automatic classification and sentiment analysis on a textual corpus of dreams, the comparison of human and AI-generated fanfiction texts, or testing the verbal creativity of large language models and compare it with human performance, etc. Pannapacker predicted as soon as 2012 that \u201cIt won\u2019t be long until the Digital Humanities are, quite simply, The Humanities\u201d. That moment has already passed.",
        "title": "Digital humanities \u0219i revolu\u021bia inteligen\u021bei artificiale",
        "authors": [
            "Anca Dinu"
        ],
        "year": "2024"
    },
    {
        "doi": "10.1590\/1809-4430-eng.agric.v43n4e20230121\/2023",
        "links": "http:\/\/www.scielo.br\/scielo.php?script=sci_arttext&pid=S0100-69162023000400307&lng=en&tlng=en",
        "abstract": "ABSTRACT Artificial Intelligence has been widely applied in data prediction for better decision making and process optimization. In the post-harvest, the control of biotic and abiotic factors is fundamental for the conservation of seed quality. Meanwhile, the tetrazolium test has been used to evaluate seed quality, however, with several limitations that can lead to evaluation errors. Thus, machine learning models can be an alternative to predict the quality of soybean seeds, with gains in the speed of obtaining results in relation to laboratory analysis methods, making the processes more robust and with low operational cost. With this, the aim of this study was to identify the best machine learning model for predicting mechanical damage, vigor and viability of soybean seeds during storage, depending on different conditions (10, 15 and 25 \u00baC), packaging (with coating and uncoated) and storage times (0, 3, 6, 9 and 12 months). M5P decision tree (M5P) and Random Forest (RF) models showed the best performance for predicting seed vigor (r = 0.75 and MAE = 10.0), and viability (r = 0.85 and MAE = 5.1), and mechanical damage to seeds (r = 0.64 and MAE = 11.2). It was concluded that the Random Forest (RF) model was the one that best predicted the results of soybean seed quality, with a more simplified and agile analysis for the development of vigor and viability of soybean seeds in storage.",
        "title": "MACHINE LEARNING MODELS FOR PREDICTING MECHANICAL DAMAGE, VIGOR AND VIABILITY OF SOYBEAN SEEDS DURING STORAGE",
        "authors": [
            "Laila R. Cirqueira",
            "Paulo C. Coradi",
            "Larissa P. R. Teodoro",
            "Paulo E. Teodoro",
            "D\u00e1gila M. Rodrigues"
        ],
        "year": "2023"
    }
]
